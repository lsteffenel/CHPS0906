{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0906/blob/main/TP1/4-Entrainer%20un%20mod%C3%A8le%20avec%20PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Doj1kSM7Fe"
      },
      "source": [
        "# Entraînement des réseaux de neurones\n",
        "\n",
        "Le réseau que nous avons construit dans la partie précédente n'est pas si intelligent, il ne sait rien de nos chiffres manuscrits. Les réseaux de neurones avec des activations non linéaires fonctionnent comme des approximateurs de fonctions universelles, où une fonction mappe votre entrée à la sortie. Par exemple, une fonction qui relie des images de chiffres manuscrits aux probabilités de classe. La puissance des réseaux de neurones est que nous pouvons les entraîner à approximer cette fonction... À vrai dire, on pourrait approximer n'importe quelle fonction à condition de disposer de suffisamment de données et de temps de calcul.\n",
        "\n",
        "<img src=\"https://github.com/udacity/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/assets/function_approx.png?raw=1\" width=500px>\n",
        "\n",
        "Au début, le réseau est très naïf, il ne connaît pas la fonction qui mappe les entrées aux sorties. Nous entraînons le réseau en lui montrant des exemples de données réelles, puis en ajustant les paramètres du réseau de manière à ce qu'il se rapproche de cette fonction.\n",
        "\n",
        "Pour trouver ces paramètres, nous devons savoir dans quelle mesure le réseau prédit mal les sorties réelles. Pour cela, nous calculons une **fonction de perte** (également appelée coût ou **loss**), une mesure de notre erreur de prédiction. Par exemple, la perte quadratique moyenne (RMSE) est souvent utilisée dans les problèmes de régression et de classification binaire\n",
        "\n",
        "$$\n",
        "\\large \\ell = \\frac{1}{2n}\\sum_i^n{\\left(y_i - \\hat{y}_i\\right)^2}\n",
        "$$\n",
        "\n",
        "où $n$ est le nombre d'exemples d'apprentissage, $y_i$ sont les vraies étiquettes et $\\hat{y}_i$ sont les étiquettes prédites.\n",
        "\n",
        "En minimisant cette perte par rapport aux paramètres du réseau, nous pouvons trouver des configurations où la perte est minimale et le réseau est capable de prédire les étiquettes correctes avec une grande précision. Nous trouvons ce minimum en utilisant un processus appelé **descente de gradient**. Le gradient est la pente de la fonction de perte et pointe dans la direction du changement le plus rapide. Pour atteindre le minimum en un minimum de temps, nous voulons ensuite suivre le gradient (vers le bas). Vous pouvez penser à cela comme descendre une montagne en suivant la pente la plus raide jusqu'à la base.\n",
        "\n",
        "<img src='https://github.com/udacity/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/assets/gradient_descent.png?raw=1' width=350px>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bKAxd6UFM7Ff"
      },
      "source": [
        "## Backpropagation\n",
        "\n",
        "Pour les réseaux à couche unique, la descente de gradient est simple à mettre en œuvre. Cependant, elle est plus compliquée pour les réseaux neuronaux multicouches plus profonds comme celui que nous avons construit. Assez compliqué pour qu'il ait fallu environ 30 ans avant que les chercheurs ne découvrent comment entraîner des réseaux multicouches.\n",
        "\n",
        "L'entraînement des réseaux multicouches se fait par **rétropropagation**, qui n'est en fait qu'une application de la règle de la chaîne du calcul. Il est plus facile de comprendre si nous convertissons un réseau à deux couches en une représentation graphique.\n",
        "\n",
        "<img src='https://github.com/udacity/deep-learning-v2-pytorch/blob/master/intro-to-pytorch/assets/backprop_diagram.png?raw=1' width=550px>\n",
        "\n",
        "Dans le passage en avant à travers le réseau, nos données et nos opérations vont ici de bas en haut. Nous passons l'entrée $x$ par une transformation linéaire $L_1$ avec des poids $W_1$ et des biais $b_1$. La sortie passe ensuite par l'opération sigmoïde $S$ et une autre transformation linéaire $L_2$. Enfin, nous calculons la perte $\\ell$. Nous utilisons la perte comme mesure de la mauvaise qualité des prédictions du réseau. L'objectif est alors d'ajuster les pondérations et les biais pour minimiser la perte.\n",
        "\n",
        "Pour entraîner les pondérations avec la descente de gradient, nous propageons le gradient de la perte vers l'arrière à travers le réseau. Chaque opération a un gradient entre les entrées et les sorties. Lorsque nous renvoyons les gradients vers l'arrière, nous multiplions le gradient entrant par le gradient de l'opération. Mathématiquement, il s'agit simplement de calculer le gradient de la perte par rapport aux pondérations à l'aide de la règle de la chaîne.\n",
        "\n",
        "$$\n",
        "\\large \\frac{\\partial \\ell}{\\partial W_1} = \\frac{\\partial L_1}{\\partial W_1} \\frac{\\partial S}{\\partial L_1} \\frac{\\partial L_2}{\\partial S} \\frac{\\partial \\ell}{\\partial L_2}\n",
        "$$\n",
        "\n",
        "Nous mettons à jour nos poids en utilisant ce gradient avec un taux d'apprentissage $\\alpha$ (**learning rate**).\n",
        "\n",
        "$$\n",
        "\\large W^\\prime_1 = W_1 - \\alpha \\frac{\\partial \\ell}{\\partial W_1}\n",
        "$$\n",
        "\n",
        "Le learning rate $\\alpha$ est défini de telle sorte que les étapes de mise à jour des poids soient suffisamment petites pour que la méthode itérative s'établisse à un minimum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4gYrg2_M7Ff"
      },
      "source": [
        "## Loss dans PyTorch\n",
        "\n",
        "Commençons par voir comment nous calculons le *loss* avec PyTorch. Grâce au module `nn`, PyTorch fournit des formules de loss telles que la perte d'entropie croisée (`nn.CrossEntropyLoss`). Vous verrez généralement la perte attribuée à `criterion`.\n",
        "\n",
        "Comme indiqué dans la dernière partie, avec un problème de classification tel que MNIST, nous utilisons la fonction softmax pour prédire les probabilités de classe. Avec une sortie softmax, vous souhaitez utiliser l'entropie croisée comme fonction de perte. Pour calculer réellement la perte, vous définissez d'abord le critère, puis vous transmettez la sortie de votre réseau et les étiquettes correctes.\n",
        "\n",
        "Quelque chose de vraiment important à noter ici. En regardant [la documentation de `nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss),\n",
        "\n",
        "> Ce critère combine `nn.LogSoftmax()` et `nn.NLLLoss()` dans une seule classe.\n",
        ">\n",
        "> L'entrée doit contenir des scores pour chaque classe.\n",
        "\n",
        "Cela signifie que nous devons transmettre la sortie brute de notre réseau pour la fonction de calcul de la perte, et non la sortie de la fonction softmax. Cette sortie brute est généralement appelée *logits* ou *scores*. Nous utilisons les logits car softmax vous donne des probabilités qui seront souvent très proches de zéro ou de un, mais les nombres à virgule flottante ne peuvent pas représenter avec précision des valeurs proches de zéro ou de un ([en savoir plus ici](https://docs.python.org/3/tutorial/floatingpoint.html)). Il est généralement préférable d'éviter de faire des calculs avec des probabilités, nous utilisons généralement des probabilités logarithmiques."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnC0iZOVM7Ff"
      },
      "outputs": [],
      "source": [
        "# The MNIST datasets are hosted on yann.lecun.com that has moved under CloudFlare protection\n",
        "# Run this script to enable the datasets download\n",
        "# Reference: https://github.com/pytorch/vision/issues/1938\n",
        "\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
        "urllib.request.install_opener(opener)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu38RvslM7Fg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9F4a70_M7Fg"
      },
      "outputs": [],
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10))\n",
        "\n",
        "# Define the loss\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ON9CdDSxM7Fg"
      },
      "source": [
        "En raison de cette spécificité de la fonction `nn.CrossEntropyLoss`, il est plus pratique de construire le modèle avec une sortie log-softmax en utilisant `nn.LogSoftmax` ou `F.log_softmax` ([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax)). Vous pouvez ensuite obtenir les probabilités réelles en prenant l'exponentielle `torch.exp(output)`. Avec une sortie log-softmax, il faut utiliser la perte `nn.NLLLoss` (*negative log likelihood loss*) ([documentation](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss)).\n",
        "\n",
        ">**Exercice :** Construisez un modèle qui renvoie le log-softmax comme sortie et calculez la perte en utilisant la perte `NLLLoss`. Notez que pour `nn.LogSoftmax` et `F.log_softmax`, vous devrez définir l'argument du mot-clé `dim` de manière appropriée. `dim=0` calcule le softmax sur les lignes, de sorte que chaque colonne totalise 1, tandis que `dim=1` calcule sur les colonnes de sorte que chaque ligne totalise 1. Pensez à ce que vous voulez que soit le résultat et choisissez `dim` de manière appropriée."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjAjLBloM7Fg"
      },
      "outputs": [],
      "source": [
        "# TODO: Build a feed-forward network\n",
        "model =\n",
        "\n",
        "# TODO: Define the loss\n",
        "criterion =\n",
        "\n",
        "### Run this to check your work\n",
        "# Get our data\n",
        "dataiter = iter(trainloader)\n",
        "\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Flatten images\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "# Forward pass, get our logits\n",
        "logits = model(images)\n",
        "# Calculate the loss with the logits and the labels\n",
        "loss = criterion(logits, labels)\n",
        "\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bbbXAi3M7Fg"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Maintenant que nous savons comment calculer une perte, comment l'utiliser pour effectuer une rétropropagation ? Torch fournit un module, `autograd`, pour calculer automatiquement les gradients des tenseurs. Nous pouvons l'utiliser pour calculer les gradients de tous nos paramètres par rapport à la perte. Autograd fonctionne en gardant une trace des opérations effectuées sur les tensors, puis en revenant en arrière dans ces opérations, en calculant les gradients au fur et à mesure. Pour vous assurer que PyTorch garde une trace des opérations sur un tensor et calcule les gradients, vous devez définir `requires_grad = True` sur le tensor. Vous pouvez le faire à la création avec le mot-clé `requires_grad`, ou à tout moment avec `x.requires_grad_(True)`.\n",
        "\n",
        "Vous pouvez également désactiver les gradients pour un bloc de code avec le contenu de `torch.no_grad()` :\n",
        "```python\n",
        "x = torch.zeros(1, require_grad=True)\n",
        ">>> avec torch.no_grad() :\n",
        "... y = x * 2\n",
        ">>> y.requires_grad\n",
        "False\n",
        "```\n",
        "\n",
        "Vous pouvez également activer ou désactiver complètement les gradients avec `torch.set_grad_enabled(True|False)`.\n",
        "\n",
        "Les gradients sont calculés par rapport à une variable `z` avec `z.backward()`. Cela effectue un passage en arrière à travers les opérations qui ont créé `z`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setCMVsQM7Fg"
      },
      "outputs": [],
      "source": [
        "x = torch.randn(2,2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbW6CzCGM7Fg"
      },
      "outputs": [],
      "source": [
        "y = x**2\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0T-a4IM7Fh"
      },
      "source": [
        "Ci-dessous, nous pouvons voir l'opération qui a créé « y », une opération de puissance « PowBackward0 »."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JHD5YprM7Fh"
      },
      "outputs": [],
      "source": [
        "## grad_fn shows the function that generated this variable\n",
        "print(y.grad_fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhpWarxM7Fh"
      },
      "source": [
        "Le module autograd garde une trace de ces opérations et sait calculer le gradient pour chacune d'elles. De cette façon, il est capable de calculer les gradients d'une chaîne d'opérations, par rapport à un tensor quelconque. Réduisons le tensor `y` à une valeur scalaire, celle de la moyenne."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lz_SzSMRM7Fh"
      },
      "outputs": [],
      "source": [
        "z = y.mean()\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcXPpzCtM7Fh"
      },
      "source": [
        "Vous pouvez vérifier les dégradés pour « x » et « y » mais ils sont actuellement vides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LOmof6ZVM7Fh"
      },
      "outputs": [],
      "source": [
        "print(x.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vazl8sA8M7Fh"
      },
      "source": [
        "Pour calculer les gradients, vous devez exécuter la méthode `.backward` sur une variable, `z` par exemple. Cela calculera le gradient de `z` par rapport à `x`\n",
        "\n",
        "$$\n",
        "\\frac{\\partial z}{\\partial x} = \\frac{\\partial}{\\partial x}\\left[\\frac{1}{n}\\sum_i^n x_i^2\\right] = \\frac{x}{2}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD7ljyrIM7Fh"
      },
      "outputs": [],
      "source": [
        "z.backward()\n",
        "print(x.grad)\n",
        "print(x/2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRkpWizEM7Fh"
      },
      "source": [
        "These gradients calculations are particularly useful for neural networks. For training we need the gradients of the cost with respect to the weights. With PyTorch, we run data forward through the network to calculate the loss, then, go backwards to calculate the gradients with respect to the loss. Once we have the gradients we can make a gradient descent step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqbZH8t6M7Fh"
      },
      "source": [
        "## Loss et Autograd ensemble\n",
        "\n",
        "Lorsque nous créons un réseau avec PyTorch, tous les paramètres sont initialisés avec `requires_grad = True`. Cela signifie que lorsque nous calculons la perte et appelons `loss.backward()`, les gradients des paramètres sont calculés. Ces gradients sont utilisés pour mettre à jour les poids avec la descente de gradient. Vous pouvez voir ci-dessous un exemple de calcul des gradients à l'aide d'un passage en arrière."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CHcrLupM7Fh"
      },
      "outputs": [],
      "source": [
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.view(images.shape[0], -1)\n",
        "\n",
        "logits = model(images)\n",
        "loss = criterion(logits, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8vETPKWM7Fh"
      },
      "outputs": [],
      "source": [
        "print('Before backward pass: \\n', model[0].weight.grad)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('After backward pass: \\n', model[0].weight.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eB0-ou-NM7Fh"
      },
      "source": [
        "## Entraînement du réseau !\n",
        "\n",
        "Il reste un dernier élément : un optimiseur, que nous utiliserons pour mettre à jour les poids avec les gradients. Nous les obtenons à partir du package [`optim`](https://pytorch.org/docs/stable/optim.html) de PyTorch. Par exemple, nous pouvons utiliser la descente de gradient stochastique avec `optim.SGD`. Vous pouvez voir comment définir un optimiseur ci-dessous."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCUJhZTYM7Fh"
      },
      "outputs": [],
      "source": [
        "from torch import optim\n",
        "\n",
        "# Optimizers require the parameters to optimize and a learning rate\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--k1xXrRM7Fh"
      },
      "source": [
        "Maintenant que nous savons comment utiliser toutes les parties individuelles, il est temps de voir comment elles fonctionnent ensemble. Considérons une seule étape d'apprentissage avant de parcourir toutes les données. Le processus général avec PyTorch :\n",
        "\n",
        "* Effectuez un passage en avant à travers le réseau\n",
        "* Utilisez la sortie du réseau pour calculer la perte\n",
        "* Effectuez un passage en arrière à travers le réseau avec `loss.backward()` pour calculer les gradients\n",
        "* Faites un pas avec l'optimiseur pour mettre à jour les poids\n",
        "\n",
        "Ci-dessous, nous allons parcourir une étape d'entraînement et imprimer les poids et les gradients afin que vous puissiez voir comment cela change. Notez que nous avons également rajouté une ligne de code `optimizer.zero_grad()`. Lorsque vous effectuez plusieurs passes en arrière avec les mêmes paramètres, les gradients sont accumulés. Cependant, quand on change les données (un nouveau batch, par exemple), il faut mettre à zéro les gradients sinon on conservera les gradients des batchs d'entraînement précédents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UR75p9BQM7Fi"
      },
      "outputs": [],
      "source": [
        "print('Initial weights - ', model[0].weight)\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "images.resize_(64, 784)\n",
        "\n",
        "# Clear the gradients, do this because gradients are accumulated\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# Forward pass, then backward pass, then update weights\n",
        "output = model(images)\n",
        "loss = criterion(output, labels)\n",
        "loss.backward()\n",
        "print('Gradient -', model[0].weight.grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyBC5XxWM7Fi"
      },
      "outputs": [],
      "source": [
        "# Take an update step and view the new weights\n",
        "optimizer.step()\n",
        "print('Updated weights - ', model[0].weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhpPdBxbM7Fi"
      },
      "source": [
        "### Entraînement pour de vrai\n",
        "\n",
        "Nous allons maintenant mettre cet algorithme dans une boucle afin de pouvoir parcourir toutes les images. Un passage sur l'ensemble des données est appelé une **Epoch**. Nous allons donc ici parcourir `trainloader` pour obtenir nos batches d'entraînement. Pour chaque batch, nous effectuerons un passage d'entraînement au cours duquel nous calculerons la perte, effectuerons un passage en arrière et mettrons à jour les poids.\n",
        "\n",
        ">**Exercice :** implémentez l'entraînement pour notre réseau. Si vous l'avez implémenté correctement, vous devriez voir la perte d'entraînement diminuer à chaque epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xza-DZSHM7Fi"
      },
      "outputs": [],
      "source": [
        "## Your solution here\n",
        "\n",
        "model = nn.Sequential(nn.Linear(784, 128),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(128, 64),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(64, 10),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
        "\n",
        "epochs = 5\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)\n",
        "\n",
        "        # TODO: Training pass\n",
        "\n",
        "        loss =\n",
        "\n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(f\"Training loss: {running_loss/len(trainloader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0FdRaWEM7Fi"
      },
      "source": [
        "Avec le réseau entraîné, nous pouvons vérifier ses prédictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbziFBh6M7Fi"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img)\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "helper.view_classify(img.view(1, 28, 28), ps)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rde8iUicM7Fi"
      },
      "source": [
        "Notre réseau est maintenant brillant. Il peut prédire avec précision les chiffres de nos images.\n",
        "\n",
        "Avant de nous lancer sur d'autres modèles plus complexes, les prochains sujets de TP vous aideront à visualiser le fonctionnement de certains composants (convolutions, pooling)."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}