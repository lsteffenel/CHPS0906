{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0906/blob/main/TP1/5-Visualiser%20une%20convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MRPHAUkXtEs"
      },
      "source": [
        "# Couche convolutionnelle\n",
        "\n",
        "Dans ce notebook nous souhaitons visualiser quatre sorties filtrées (également appelées cartes d'activation) d'une couche convolutionnelle.\n",
        "\n",
        "Pour cela, *nous* définissons quatre filtres qui sont appliqués à une image d'entrée en initialisant les **poids** d'une couche convolutionnelle.\n",
        "\n",
        "Bien qu'amusant, on n'a pas à faire ça. En effet, un CNN entraîné apprendra les valeurs de ces poids tout seul, sans besoin qu'on initialise les filtres.\n",
        "\n",
        "<img src='https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/conv-visualization/notebook_ims/conv_layer.gif?raw=1' height=60% width=60% />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Re243sNzXtEu"
      },
      "source": [
        "### Importer une image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayHpWziKXtEu"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# TODO: Déposer une image dans l'onglet \"Fichiers\". Ensuite, renseignez le nom du fichier ci-dessous\n",
        "img_path = 'car_sdc.png'\n",
        "\n",
        "# load color image\n",
        "bgr_img = cv2.imread(img_path)\n",
        "# convert to grayscale\n",
        "gray_img = cv2.cvtColor(bgr_img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "# normalize, rescale entries to lie in [0,1]\n",
        "gray_img = gray_img.astype(\"float32\")/255\n",
        "\n",
        "# plot image\n",
        "plt.imshow(gray_img, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXxZUJyAXtEv"
      },
      "source": [
        "### Définir des filtres"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oa62dolRXtEv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "## TODO: Vous pouvez essayer autres filtres\n",
        "filter_vals = np.array([[-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1], [-1, -1, 1, 1]])\n",
        "\n",
        "print('Filter shape: ', filter_vals.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ht1UYNQXtEw"
      },
      "outputs": [],
      "source": [
        "# Defining four different filters,\n",
        "# all of which are linear combinations of the `filter_vals` defined above\n",
        "\n",
        "# define four filters\n",
        "filter_1 = filter_vals\n",
        "filter_2 = -filter_1\n",
        "filter_3 = filter_1.T\n",
        "filter_4 = -filter_3\n",
        "filters = np.array([filter_1, filter_2, filter_3, filter_4])\n",
        "\n",
        "# For an example, print out the values of filter 1\n",
        "print('Filter 1: \\n', filter_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GLN_YHCXtEw"
      },
      "outputs": [],
      "source": [
        "# visualize all four filters\n",
        "fig = plt.figure(figsize=(10, 5))\n",
        "for i in range(4):\n",
        "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(filters[i], cmap='gray')\n",
        "    ax.set_title('Filter %s' % str(i+1))\n",
        "    width, height = filters[i].shape\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            ax.annotate(str(filters[i][x][y]), xy=(y,x),\n",
        "                        horizontalalignment='center',\n",
        "                        verticalalignment='center',\n",
        "                        color='white' if filters[i][x][y]<0 else 'black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryBsBYpUXtEw"
      },
      "source": [
        "## Définir une couche convolutionnelle\n",
        "\n",
        "Les différentes couches qui composent tout réseau neuronal sont documentées, [ici](http://pytorch.org/docs/stable/nn.html). Pour un réseau neuronal convolutionnel, nous commencerons par définir :\n",
        "* Couche convolutionnelle\n",
        "\n",
        "Initialisez une seule couche convolutionnelle afin qu'elle contienne tous vos filtres créés. Notez que vous n'entraînez pas ce réseau ; vous initialisez les poids dans une couche convolutionnelle afin de pouvoir visualiser ce qui se passe après un passage en avant à travers ce réseau !\n",
        "\n",
        "#### `__init__` et `forward`\n",
        "Pour définir un réseau neuronal dans PyTorch, vous définissez les couches d'un modèle dans la fonction `__init__` et définissez le comportement en avant d'un réseau qui applique ces couches initialisées à une entrée (`x`) dans la fonction `forward`. Dans PyTorch, nous convertissons toutes les entrées dans le type de données Tensor, qui est similaire à un type de données de liste en Python.\n",
        "\n",
        "Ci-dessous, la structure d'une classe appelée `Net` possède une couche convolutionnelle pouvant contenir quatre filtres en niveaux de gris 4x4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XMHg_MB0XtEx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define a neural network with a single convolutional layer with four filters\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, weight):\n",
        "        super(Net, self).__init__()\n",
        "        # initializes the weights of the convolutional layer to be the weights of the 4 defined filters\n",
        "        k_height, k_width = weight.shape[2:]\n",
        "        # assumes there are 4 grayscale filters\n",
        "        self.conv = nn.Conv2d(1, 4, kernel_size=(k_height, k_width), bias=False)\n",
        "        self.conv.weight = torch.nn.Parameter(weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # calculates the output of a convolutional layer\n",
        "        # pre- and post-activation\n",
        "        conv_x = self.conv(x)\n",
        "        activated_x = F.relu(conv_x)\n",
        "\n",
        "        # returns both layers\n",
        "        return conv_x, activated_x\n",
        "\n",
        "# instantiate the model and set the weights\n",
        "weight = torch.from_numpy(filters).unsqueeze(1).type(torch.FloatTensor)\n",
        "model = Net(weight)\n",
        "\n",
        "# print out the layer in the network\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OgeOHxRXtEx"
      },
      "source": [
        "### Visualiser la sortie de chaque filtre\n",
        "\n",
        "Nous allons d'abord définir une fonction d'assistance, `viz_layer`, qui prend en compte une couche spécifique et un nombre de filtres (argument facultatif) et affiche la sortie de cette couche une fois qu'une image a été transmise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "CeaVdzlsXtEx"
      },
      "outputs": [],
      "source": [
        "# helper function for visualizing the output of a given layer\n",
        "# default number of filters is 4\n",
        "def viz_layer(layer, n_filters= 4):\n",
        "    fig = plt.figure(figsize=(20, 20))\n",
        "\n",
        "    for i in range(n_filters):\n",
        "        ax = fig.add_subplot(1, n_filters, i+1, xticks=[], yticks=[])\n",
        "        # grab layer outputs\n",
        "        ax.imshow(np.squeeze(layer[0,i].data.numpy()), cmap='gray')\n",
        "        ax.set_title('Output %s' % str(i+1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3Jtw6pyXtEx"
      },
      "source": [
        "Regardons la sortie d’une couche convolutive, avant et après l’application d’une fonction d’activation ReLu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJDT4p7NXtEx"
      },
      "outputs": [],
      "source": [
        "# plot original image\n",
        "plt.imshow(gray_img, cmap='gray')\n",
        "\n",
        "# visualize all filters\n",
        "fig = plt.figure(figsize=(12, 6))\n",
        "fig.subplots_adjust(left=0, right=1.5, bottom=0.8, top=1, hspace=0.05, wspace=0.05)\n",
        "for i in range(4):\n",
        "    ax = fig.add_subplot(1, 4, i+1, xticks=[], yticks=[])\n",
        "    ax.imshow(filters[i], cmap='gray')\n",
        "    ax.set_title('Filter %s' % str(i+1))\n",
        "\n",
        "\n",
        "# convert the image into an input Tensor\n",
        "gray_img_tensor = torch.from_numpy(gray_img).unsqueeze(0).unsqueeze(1)\n",
        "\n",
        "# get the convolutional layer (pre and post activation)\n",
        "conv_layer, activated_layer = model(gray_img_tensor)\n",
        "\n",
        "# visualize the output of a conv layer\n",
        "viz_layer(conv_layer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWGmboziXtEx"
      },
      "source": [
        "#### Activation ReLu\n",
        "\n",
        "Dans ce modèle, nous avons utilisé une fonction d'activation qui met à l'échelle la sortie de la couche convolutionnelle. Nous avons choisi une fonction ReLu pour ce faire, et cette fonction transforme simplement toutes les valeurs de pixels négatives en 0 (noir). Voir l'équation illustrée ci-dessous pour les valeurs de pixels d'entrée, `x`.\n",
        "\n",
        "<img src='https://github.com/udacity/deep-learning-v2-pytorch/blob/master/convolutional-neural-networks/conv-visualization/notebook_ims/relu_ex.png?raw=1' height=50% width=50% />"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKsH2TRkXtEy"
      },
      "outputs": [],
      "source": [
        "# Après que ReLU ait été activée\n",
        "# voici la sortie d'une couche convolutionnelle après activation\n",
        "viz_layer(activated_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "heWAu7D6XtEy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}