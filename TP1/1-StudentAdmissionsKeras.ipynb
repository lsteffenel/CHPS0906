{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0906/blob/main/TP1/StudentAdmissionsKeras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G326P1Dp2EeO"
      },
      "source": [
        "# Prédire les admissions des étudiants avec des réseaux neuronaux dans Keras\n",
        "Dans ce bloc-notes, nous prédisons les admissions des étudiants aux études supérieures à l'UCLA (Université de Californie à Los Angeles) en fonction de trois éléments de données :\n",
        "- Scores GRE (test)\n",
        "- Scores GPA (notes)\n",
        "- Classement (1-4)\n",
        "\n",
        "L'ensemble de données provient à l'origine d'ici : http://www.ats.ucla.edu/\n",
        "\n",
        "## Chargement des données\n",
        "Pour charger les données et les formater correctement, nous utiliserons Pandas et Numpy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNxmeveO2EeP"
      },
      "outputs": [],
      "source": [
        "# Importing pandas and numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Reading the csv file into a pandas DataFrame\n",
        "data = pd.read_csv('https://github.com/lsteffenel/CHPS0906/raw/refs/heads/main/TP1/data/student_data.csv')\n",
        "\n",
        "# Printing out the first 10 rows of our data\n",
        "data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3apJ6Mc2EeQ"
      },
      "source": [
        "## Visualisation des données\n",
        "\n",
        "Commençons par créer une visualisation de nos données pour voir à quoi elles ressemblent. Pour obtenir un graphique en 2D, ignorons le rang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gMwRIVa2EeQ"
      },
      "outputs": [],
      "source": [
        "# Importing matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Function to help us plot\n",
        "def plot_points(data):\n",
        "    X = np.array(data[[\"gre\",\"gpa\"]])\n",
        "    y = np.array(data[\"admit\"])\n",
        "    admitted = X[np.argwhere(y==1)]\n",
        "    rejected = X[np.argwhere(y==0)]\n",
        "    plt.scatter([s[0][0] for s in rejected], [s[0][1] for s in rejected], s = 25, color = 'red', edgecolor = 'k')\n",
        "    plt.scatter([s[0][0] for s in admitted], [s[0][1] for s in admitted], s = 25, color = 'cyan', edgecolor = 'k')\n",
        "    plt.xlabel('Test (GRE)')\n",
        "    plt.ylabel('Grades (GPA)')\n",
        "\n",
        "# Plotting the points\n",
        "plot_points(data)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuYHNg652EeQ"
      },
      "source": [
        "En gros, il semble que les élèves ayant obtenu les meilleures notes et les meilleurs tests aient réussi, tandis que ceux ayant obtenu les pires notes ont échoué, mais les données ne sont pas aussi bien séparées que nous l'espérions. Peut-être serait-il utile de prendre en compte le rang ? Créons 4 graphiques, chacun pour chaque rang."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7HCjcBl2EeQ"
      },
      "outputs": [],
      "source": [
        "# Separating the ranks\n",
        "data_rank1 = data[data[\"rank\"]==1]\n",
        "data_rank2 = data[data[\"rank\"]==2]\n",
        "data_rank3 = data[data[\"rank\"]==3]\n",
        "data_rank4 = data[data[\"rank\"]==4]\n",
        "\n",
        "# Plotting the graphs\n",
        "plot_points(data_rank1)\n",
        "plt.title(\"Rank 1\")\n",
        "plt.show()\n",
        "plot_points(data_rank2)\n",
        "plt.title(\"Rank 2\")\n",
        "plt.show()\n",
        "plot_points(data_rank3)\n",
        "plt.title(\"Rank 3\")\n",
        "plt.show()\n",
        "plot_points(data_rank4)\n",
        "plt.title(\"Rank 4\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfwxsjNk2EeQ"
      },
      "source": [
        "Cela semble plus prometteur car le rang est bas, plus le taux d'acceptation est élevé (et oui, si vous pensez bien, rang 1 est plus petit que rang 4). Utilisons le rang comme l'une de nos entrées. Cependant, pour éviter des biais en fonction des valeurs numériques, nous devons encoder les rangs en format `one-hot encoding`.\n",
        "\n",
        "## One-hot encoding du rang\n",
        "Pour cela, nous utiliserons la fonction `get_dummies` dans pandas. Il est aussi possible de faire appel à scikit-learn, si vous voulez plus de flexibilité."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX8rHcre2EeR"
      },
      "outputs": [],
      "source": [
        "# Make dummy variables for rank\n",
        "one_hot_data = pd.concat([data, pd.get_dummies(data['rank'], prefix='rank')], axis=1)\n",
        "\n",
        "# Drop the previous rank column\n",
        "one_hot_data = one_hot_data.drop('rank', axis=1)\n",
        "\n",
        "# Print the first 10 rows of our data\n",
        "one_hot_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbdEljux2EeR"
      },
      "source": [
        "## Mise à l'échelle des données\n",
        "L'étape suivante consiste à mettre à l'échelle les données.\n",
        "Nous remarquons que la plage des notes est de 1.0 à 4.0, tandis que la plage des scores aux tests est d'environ 200 à 800, ce qui est beaucoup plus large.\n",
        "\n",
        "Cela rend leur gestion difficile pour un réseau neuronal car la différence d'ordre de grandeur peut jouer en faveur des scores test.\n",
        "\n",
        "Afin de limiter cet écart, ajustons nos deux caractéristiques dans une plage de 0 à 1, en divisant les notes par 4.0 et le score au test par 800."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ImUq2XG32EeR"
      },
      "outputs": [],
      "source": [
        "# Copying our data\n",
        "processed_data = one_hot_data[:]\n",
        "\n",
        "# Scaling the columns\n",
        "processed_data['gre'] = processed_data['gre']/800\n",
        "processed_data['gpa'] = processed_data['gpa']/4.0\n",
        "processed_data[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR3M6w4L2EeR"
      },
      "source": [
        "## Répartition des données en un ensemble d'entraînement et un ensemble de tests\n",
        "\n",
        "Afin de tester notre algorithme, nous allons repartir les données en un ensemble d'entraînement et un ensemble de tests. La taille de l'ensemble de tests sera de 10% des données totales."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwIH1i_l2EeR"
      },
      "outputs": [],
      "source": [
        "sample = np.random.choice(processed_data.index, size=int(len(processed_data)*0.9), replace=False)\n",
        "train_data, test_data = processed_data.iloc[sample], processed_data.drop(sample)\n",
        "\n",
        "print(\"Number of training samples is\", len(train_data))\n",
        "print(\"Number of testing samples is\", len(test_data))\n",
        "print(train_data[:10])\n",
        "print(test_data[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCIO_CUo2EeR"
      },
      "source": [
        "## Séparation des données en caractéristiques et cibles (étiquettes)\n",
        "\n",
        "Maintenant, comme dernière étape avant l'entraînement, nous allons diviser les données en caractéristiques (X) et cibles (y).\n",
        "\n",
        "De plus, dans Keras, nous devons indiquer que la sortie (`admit`) représente une catégorie et pas une valeur numérique. Nous le ferons avec la fonction `to_categorical`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZF2VfVzl2EeR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Separate data and one-hot encode the output\n",
        "# Note: We're also turning the data into numpy arrays, in order to train the model in Keras\n",
        "features = np.array(train_data.drop('admit', axis=1)).astype('float32')\n",
        "targets = np.array(keras.utils.to_categorical(train_data['admit'], 2))\n",
        "features_test = np.array(test_data.drop('admit', axis=1)).astype('float32')\n",
        "targets_test = np.array(keras.utils.to_categorical(test_data['admit'], 2))\n",
        "\n",
        "print(features[:10])\n",
        "print(targets[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LibVc0p62EeR"
      },
      "source": [
        "## Définition de l'architecture du modèle\n",
        "C'est ici que nous utilisons Keras pour construire notre réseau de neurones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7nysGNg2EeR"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "from keras import Layer\n",
        "from keras import Optimizer\n",
        "\n",
        "# Building the model\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(128, activation='relu', input_shape=(6,)))\n",
        "model.add(keras.layers.Dropout(.2))\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(.1))\n",
        "model.add(keras.layers.Dense(2, activation='softmax'))\n",
        "\n",
        "# Compiling the model\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy','recall'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prenez 2 minutes et refléchissez à l'architecture proposée.\n",
        "- quel est son type (dense, convolutionnelle) ?\n",
        "- le nombre de neurones dans chaque couche vous semble adéquat ?\n",
        "- comment feriez-vous pour décrire cette architecture en mode Functional (ici c'est en mode Sequential) ?"
      ],
      "metadata": {
        "id": "KVY-coVD95wp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKux-bSR2EeR"
      },
      "source": [
        "\n",
        "\n",
        "## Entraînement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGaPb8-F2EeS"
      },
      "outputs": [],
      "source": [
        "# Training the model\n",
        "model.fit(features, targets, epochs=200, batch_size=100, verbose=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAu7bayQ2EeS"
      },
      "source": [
        "## Évaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xq7whCxh2EeS"
      },
      "outputs": [],
      "source": [
        "# Evaluating the model on the training and testing set\n",
        "score = model.evaluate(features, targets)\n",
        "print(\"\\n Training Accuracy:\", score[1])\n",
        "score = model.evaluate(features_test, targets_test)\n",
        "print(\"\\n Testing Accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.metrics_names"
      ],
      "metadata": {
        "id": "5DLNdOnT_BWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A votre avis, est-ce que ce modèle a une bonne accuracy ? Comment feriez-vous pour rajouter le `recall` à la liste de métriques à surveiller pendant l'entraînement ?"
      ],
      "metadata": {
        "id": "llZczelf-w76"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*vous pouvez modifier le code pour afficher l'accuracy et le recall*"
      ],
      "metadata": {
        "id": "XPAG747F_la3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2YN78-W2EeS"
      },
      "source": [
        "## Défi : Jouez avec les paramètres !\n",
        "Nous avons pris plusieurs décisions comme par exemple le nombre de couches, la taille des couches, le nombre d'époques, etc.\n",
        "\n",
        "C'est à votre tour de jouer avec les paramètres ! Pouvez-vous améliorer la précision ?\n",
        "\n",
        "Essayez aussi d'autrers paramètres :\n",
        "- Fonction d'activation : relu et sigmoïde\n",
        "- Fonction de perte : categorical_crossentropy, mean_squared_error\n",
        "- Optimiseur : rmsprop, adam, ada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "2ZJBul2T2EeS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
